# GAN-INTRO
GAN 就完了 ！

### 什么是GAN ？

**GAN：** 是通过**对抗训练**的方式来使得**生成网络产生的样本**服从**真实数据分布**。而其网络的关键在于**生成网络**和**判别网络**的对抗学习。

- **判别网络** ，目标是尽量准确地判断一个样本是来自于真实数据还是由生成网络产生；
- **生成网络** ，目标是尽量生成判别网络无法区分来源的样本。

这两个目标相反的网络不断地进行交替训练。 当最后收敛时，如果判别网络再也无法判断出一个样本的来源，那么也就等价于生成网络可以生成符合真实数据分布的样本。

![GAN](./figs/GAN.png)

### GAN思路 ？ ？

直观的来讲可以把**生成网络**想象为一位莫奈风格的**名画伪造者**，把**判别网络**当作一位莫奈风格的**艺术鉴定师**。 整个训练的过程可以理解为伪造者和鉴定师不断学习成长的过程，主要流程如下：

- 一开始，**伪造者**是个刚入门的小白，网络中的参数都是随机初始化的，因此只会在画布上画出混乱的颜色；
- 之后他将**自己的一些作品**和莫**奈风格的真品**混在一起，请**艺术鉴定师**进行真实性评估；
- **艺术鉴定师**通过真实的数据集学习，一开始很容易鉴别出了赝品，并**向伪造者反馈**告诉他哪些看起来像真迹、哪些看起来不想真迹。
- **伪造者**根据这些**反馈**，**改进**自己的赝品。

![GAN直观理解](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3.png)

### GAN网络结构 ？

GAN从网络的角度来看，它由**两部分**组成。

- **生成器网络**：它一个潜在空间的随机向量作为输入，并将其解码为一张合成图像。
- **判别器网络**：以一张图像（真实的或合成的均可）作为输入，并预测该图像来自训练集还是来自生成器网络。

<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/GAN%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6.png" alt="GAN网络框架" style="zoom: 50%;" />



### 损失函数 ？ Loss Function

从GAN的架构图可知，控制生成器或判别器的关键是**损失函数**，而如何定义损失函数就成为整个GAN的关键！！

我们的目标是既要不断**提升判断器辨别是非或真假的能力**，又要不断**提升生成器不断提升图像质量**，使判别器越来越难判别。



### 符号说明

| 符号       | 说明                                                         |
| ---------- | :----------------------------------------------------------- |
| x          | 输入到某个网络的样本（比如说一张图）                         |
| y          | 样本标签，真实为1，生成样本为0                               |
| θ          | 生成网络参数                                                 |
| ϕ          | 判断网络参数                                                 |
| z          | 低维空间z中的一个样本（一个低维tensor）                      |
| pr(x)      | x来自于真实分布的概率                                        |
| pθ(x)      | x来自于生成模型的概率                                        |
| P(z)       | 低维空间 𝒵 中的一个简单容易采样的分布，通常为标准多元正态分布N(0, 1) |
| G(**z**;θ) | 将低维tensor  z 输入到参数为 θ 的生成网络中，得到一个虚假的生成样本（可以理解为一张图画） |
| D(**x**;ϕ) | 将样本 𝒙 输入到参数为 ϕ 的判别网络中，得到一个是否为真样本的概率 |



### 判断网络的损失函数 ？

判断网络（Discriminator Network）`D(𝒙; ϕ)` 的目标是区分出一个样本 𝒙  是来自真实分布还是来自于生成模型

实际上就是一个二分类的分类器，

简单来说就是一个分类问题。

![GAN的判别网络](.\figs\判别网络.png)

判断网络 D(𝒙; ϕ)  的输出是 𝒙 属于真实数据分布的概率：

`P(y=1 | 𝒙 ) = D(𝒙; ϕ)`

那么样本来自于生成模型的概率为：

`P(y=0 | 𝒙 ) = 1 - D(𝒙; ϕ)`

给定一个样本(x, 𝑦)(x,y) , 𝑦 = {1, 0}表示其来自于真实样本还是生成样本，

判别网络的**目标函数**为**最小化交叉熵**，即 ：

ϕmin−(E**x**[ylogp(y=1∣**x**)+(1−y)logp(y=0∣**x**)])

假设分布 𝑝(𝒙) 是由分布 p_𝑟(𝒙)pr(**x**) 和分布 p_{\theta}(𝒙)pθ(**x**) 等比例混合而成，即 ：
$$
p(𝒙) =\frac{1}{2}\left(p_{r}(\boldsymbol{x})+p_{\theta}(\boldsymbol{x})\right)
$$
则上式等价于：

ϕmaxE**x**∼pr(**x**)[logD(**x**;ϕ)]+E**x**′∼pθ(**x**′)[log(1−D(**x**′;ϕ))] = ϕmaxE**x**∼pr(**x**)[logD(**x**;ϕ)]+E**z**∼p(z)[log(1−D(G(**z**;θ);ϕ))]

代码：

```python
# D表示判别器、G为生成器、real_labels、fake_labels分别表示真图像标签、假图像标签。
# images是真图像，z是从潜在空间随机采样的向量，通过生成器得到假图像。

# 定义判别器对真图像的损失函数 
outputs = D(images) 
# 二分类交叉熵损失函数
d_loss_real = criterion(outputs, real_labels) 
real_score = outputs 

# 定义生成器对假图像（即由潜在空间点生成的图像）的损失函数
# 由随机向量通过生成器网络生成假图像
z = torch.randn(batch_size, latent_size).to(device) 
fake_images = G(z) 

# 定义判别器对假图像的损失函数 
outputs = D(fake_images) 
d_loss_fake = criterion(outputs, fake_labels) 
fake_score = outputs 

# 得到总的损失函数 
d_loss = d_loss_real + d_loss_fake 
```



### 生成网络的损失函数 ？

生成网络（Generator Network）的目标刚好和判别网络相反，即让判别网络**将自己生成的样本判别为真实样本**。

maxθ(E**z**∼p(z)[logD(G(**z**;θ);ϕ)]) = minθ(E**z**∼p(z)[log(1−D(G(**z**;θ);ϕ))])

上面面的这两个目标函数是等价的。但是在实际训练时，**一般使用前者**，因为其梯度性质更好。

<img src="./figs/log.png" alt="log函数" style="zoom:50%;" />

我们知道，函数log(𝑥), 𝑥 ∈ (0, 1)在𝑥 接近1时的梯度要比接近0时的梯度小很多，接近“饱和”区间。 

这样，当判别网络 𝐷 以很高的概率认为生成网络 𝐺 产生的样本是“假”样本，

即 ( 1 − D ( G ( **z** ; θ ) ; ϕ ) ) → 1，

这时目标函数关于𝜃 的梯度反而很小，从而不利于优化。

**而一开始判别器是很容易鉴别仿造数据的，**

**因此D ( G ( z ; θ ) ; ϕ ) 的初始值是在靠近 0 的左端。**

而对于刚开始训练的模型，我们希望在初期 D ( G ( **z** ; θ ) ; ϕ ) 能够快速地更新，

但不幸的是，

目标函数 log ( 1 − D(x) ) 左端刚好是平缓的区域，

依据梯度下降原理这会阻碍 D(x) 的快速更新。

**生成器的损失函数要这样定义才能使其越来越向真图像靠近**

**以真图像为标签即可。具体代码如下：**

```python
# 定义p(Z)是一个高斯分布
z = torch.randn(batch_size, latent_size).to(device) 
# 由随机向量通过生成器网络生成假图像
fake_images = G(z) 
# 定义判断器对假图像的损失函数 
outputs = D(fake_images)
# 注意此处和判别器不同,判别器为fake_labels,而生成器为real_labels.即其优化目标是使得生成图片能尽可能判定为真.
g_loss = criterion(outputs, real_labels)
```



### 最小化最大化游戏（Minimax Game）

将判别网络和生成网络**合并**，整个生成对抗网络的目标函数看作是**最小化最大化游戏（Minimax Game）**。
$$
minθ
​
  

maxϕ
​
 (E 
x∼p 
r
​
 (x)
​
 [logD(x;ϕ)]+E 
x∼p 
θ
​
 (x)
​
 [log(1−D(x;ϕ))]) \\ 
 = 

minθ
​
  

maxϕ
​
 (E 
x∼p 
r
​
 (x)
​
 [logD(x;ϕ)]+E 
z∼p(z)
​
 [log(1−D(G(z;θ);ϕ))]) \\ 
 = 

minθ
​
  

maxϕ
​
 (E 
x∼p 
r
​
 (x)
​
 [logD(x;ϕ)]−E 
z∼p(z)
​
 [log(D(G(z;θ);ϕ))]) 
Non−saturating
​
 
​
$$
但是**如果判断器的能力过于好**，

D(G(**z**;θ)趋近于0时，会导致max的值趋近一个常数。

这时即使采取目标函数关于𝜃 的梯度变化较大的 maxθ ( E **z**∼p(z) [ log D ( G ( **z** ; θ ) ; ϕ )] ) 的损失函数，

由于最优的判别器D^{\star}D⋆对所有生成的数据的输出都为0。

因此生成网络的梯度消失。



### 训练（Train）

生成对抗网络的训练比较难，往往不太稳定。

一般情况下，**需要平衡**两个网络的能力。

- 对于判别网络来说，**一开始的判别能力不能太强**，否则难以提升生成网络的能力。但是，**判别网络的判别能力也不能太弱**，否则针对它训练的生成网络也不会太好。在训练时需要使用一些Tricks，使得在每次迭代中，**判别网络比生成网络的能力强一些**，但又不能强太多。
- 而生成网络更新一次生成对抗网络的训练流程如下算法所示。每次迭代时，**判别网络更新 𝐾 次** ，即首先要保证判别网络足够强才能开始训练生成网络。在实践中**𝐾 是一个超参数**，其取值一般取决于具体任务。

<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/GAN%E7%9A%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.png" alt="GAN的训练过程" style="zoom:50%;" />
